{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ca78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeHateBERT:\n",
    "    \"\"\"Lasso model using HateBERT embeddings to detect hate speech.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize classifier with HateBERT and L1-penalized logistic regression.\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "        self.model_encoder = AutoModel.from_pretrained(\"GroNLP/hateBERT\")\n",
    "        self.model = LogisticRegression(solver=\"liblinear\", max_iter=1000)\n",
    "\n",
    "    def embed(self, texts: pd.Series) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Embed text using HateBERT [CLS] token embeddings.\n",
    "\n",
    "        Args:\n",
    "            texts (pd.Series): Input phrases.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Sentence embeddings.\n",
    "        \"\"\"\n",
    "        self.model_encoder.eval()\n",
    "        embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for text in texts:\n",
    "                encoded = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "                output = self.model_encoder(**encoded)\n",
    "                cls_embedding = output.last_hidden_state[:, 0, :]\n",
    "                embeddings.append(cls_embedding.squeeze().numpy())\n",
    "\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    def train(self, X: pd.Series, y: pd.Series) -> None:\n",
    "        X_embed = self.embed(X)\n",
    "        self.model.fit(X_embed, y)\n",
    "\n",
    "    def predict_proba(self, X: pd.Series) -> pd.Series:\n",
    "        X_embed = self.embed(X)\n",
    "        proba = self.model.predict_proba(X_embed)[:, 1]\n",
    "        return pd.Series(proba, index=X.index)\n",
    "\n",
    "    def evaluate(self, X_test: pd.Series, y_test: pd.Series) -> None:\n",
    "        proba = self.predict_proba(X_test)\n",
    "        y_pred = (proba >= 0.25).astype(int)\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06951c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train_data.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_data_clean.csv\")\n",
    "\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "model = RidgeHateBERT()\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "X_test = test_df[\"comment\"]\n",
    "y_test = test_df[\"isHate\"].astype(int)\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Test Data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd97347",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, test_probs)\n",
    "avg_precision = average_precision_score(y_test, test_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"Avg Precision = {avg_precision:.2f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve - Test Data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0584e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = (test_probs >= 0.25).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Hate\", \"Hate\"])\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Test Data\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
